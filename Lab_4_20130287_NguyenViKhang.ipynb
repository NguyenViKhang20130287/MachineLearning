{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenViKhang20130287/MachineLearning/blob/main/Lab_4_20130287_NguyenViKhang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00eff386-94bb-4fcc-d60e-642247f571ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer  \n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Colab Notebooks'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data4 = datasets.load_iris()\n",
        "X_train=data4.data\n",
        "Y_train=data4.target\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train, Y_train) \n",
        "Y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(Y_train, Y_pred)\n",
        "print(Y_pred)\n",
        "print(cm)\n",
        "print (\"Accuracy : \", accuracy_score(Y_train, Y_pred)) \n",
        "print (\"Precision : \", precision_score(Y_train, Y_pred, average=None))\n",
        "ConfusionMatrixDisplay.from_predictions(Y_train,Y_pred)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5e0a2df7-fd9b-4e35-d50b-34e1cc644048"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5cee8796b491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = datasets.load_digits()\n",
        "X_train2=mnist.data\n",
        "Y_train2=mnist.target\n",
        "classifier = LogisticRegression(random_state = 0) \n",
        "classifier.fit(X_train2, Y_train2) \n",
        "Y_pred2 = classifier.predict(X_train2)\n",
        "cm = confusion_matrix(Y_train2, Y_pred2) \n",
        "print(Y_pred2)\n",
        "print(cm)\n",
        "print (\"Accuracy : \", accuracy_score(Y_train2, Y_pred2))\n",
        "print (\"Precision : \", precision_score(Y_train2, Y_pred2,average=None))\n",
        "ConfusionMatrixDisplay.from_predictions(Y_train2,Y_pred2)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_range=range(1,30,2)\n",
        "accs=[]\n",
        "prec=[]\n",
        "recall=[]\n",
        "f1=[]\n",
        "for k in k_range:\n",
        "  kNN1= KNeighborsClassifier(n_neighbors=k)\n",
        "  kNN1.fit(X_train,Y_train)\n",
        "  y_pred3 = kNN1.predict(X_train)\n",
        "  accs.append(accuracy_score(Y_train, y_pred3))\n",
        "  prec.append(precision_score(Y_train, y_pred3, average='macro'))\n",
        "  recall.append(recall_score(Y_train, y_pred3, average='macro'))\n",
        "  f1.append(f1_score(Y_train, y_pred3,average='macro'))\n",
        "plt.plot(k_range, accs, label='Accuracy')\n",
        "plt.plot(k_range, prec, label='Precision')\n",
        "plt.plot(k_range, recall, label='Recall')\n",
        "plt.plot(k_range, f1, label='F1')\n",
        "plt.xlabel(\"k\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accs2=[]\n",
        "prec2=[]\n",
        "recall2=[]\n",
        "f12=[]\n",
        "for k in k_range:\n",
        "  kNN2= KNeighborsClassifier(n_neighbors=k)\n",
        "  kNN2.fit(X_train2,Y_train2)\n",
        "  y_pred4 = kNN2.predict(X_train2)\n",
        "  accs2.append(accuracy_score(Y_train2, y_pred4))\n",
        "  prec2.append(precision_score(Y_train2, y_pred4, average='macro'))\n",
        "  recall2.append(recall_score(Y_train2, y_pred4, average='macro'))\n",
        "  f12.append(f1_score(Y_train2, y_pred4, average='macro'))\n",
        "plt.plot(k_range, accs2, label='Accuracy')\n",
        "plt.plot(k_range, prec2, label='Precision')\n",
        "plt.plot(k_range, recall2, label='Recall')\n",
        "plt.plot(k_range, f12, label='F1')\n",
        "plt.xlabel(\"k\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data5 = pd.read_csv('spambase.csv', header=None)\n",
        "Y_train5 = data5.iloc[: , -1]\n",
        "X_train5 = data5.iloc[: , :57]\n",
        "accs_5=[]\n",
        "prec_5=[]\n",
        "recall_5=[]\n",
        "f1_5=[]\n",
        "tree_model = DecisionTreeClassifier()\n",
        "kNN_model= KNeighborsClassifier()\n",
        "regress_model = LogisticRegression()\n",
        "tree_model.fit(X_train5, Y_train5)\n",
        "kNN_model.fit(X_train5, Y_train5)\n",
        "regress_model.fit(X_train5, Y_train5)\n",
        "y_predTree = tree_model.predict(X_train5)\n",
        "y_predkNN =kNN_model.predict(X_train5)\n",
        "y_predRegres =regress_model.predict(X_train5)\n",
        "accs_5.append(accuracy_score(Y_train5, y_predTree))\n",
        "accs_5.append(accuracy_score(Y_train5, y_predkNN))\n",
        "accs_5.append(accuracy_score(Y_train5, y_predRegres))\n",
        "prec_5.append(precision_score(Y_train5, y_predTree, average='macro'))\n",
        "prec_5.append(precision_score(Y_train5, y_predkNN, average='macro'))\n",
        "prec_5.append(precision_score(Y_train5, y_predRegres, average='macro'))\n",
        "recall_5.append(recall_score(Y_train5, y_predTree, average='macro'))\n",
        "recall_5.append(recall_score(Y_train5, y_predkNN, average='macro'))\n",
        "recall_5.append(recall_score(Y_train5, y_predRegres, average='macro'))\n",
        "f1_5.append(f1_score(Y_train5, y_predTree, average='macro'))\n",
        "f1_5.append(f1_score(Y_train5, y_predkNN, average='macro'))\n",
        "f1_5.append(f1_score(Y_train5, y_predRegres, average='macro'))\n",
        "List = pd.DataFrame({ 'Accuracy': accs_5, 'Precision': prec_5, 'Recall': recall_5, 'F1': f1_5}, index=['DecisionTree','KNeighbors', 'LogisticReg'])\n",
        "print(List)\n",
        "print('\\nDecisionTree')\n",
        "print(confusion_matrix(Y_train5, y_predTree))\n",
        "print('\\nKNeighbors')\n",
        "print(confusion_matrix(Y_train5, y_predkNN))\n",
        "print('\\nLogisticReg')\n",
        "print(confusion_matrix(Y_train5, y_predRegres))"
      ],
      "metadata": {
        "id": "W_1v_ivR2f6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}